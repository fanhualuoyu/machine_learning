{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -3.1624,   5.8284,   8.0172,  ...,   4.7769,   6.4400,   6.3647],\n",
       "         [  2.1417,  -1.7755,  -6.4943,  ...,   6.7356,   0.0291,  -3.5957],\n",
       "         [  2.5677,   3.5388,   0.1226,  ...,  -7.9781,   2.1954,  -8.6682],\n",
       "         ...,\n",
       "         [ -7.0087,   4.2625,  -0.9824,  ...,   0.2429,  -3.8899,   2.4892],\n",
       "         [  4.6992,   1.1544,   2.5803,  ...,   2.7860,   2.7565,  -3.3417],\n",
       "         [  7.9844,  11.4087,   2.1051,  ...,   3.4665,  -1.1725,  -8.7679]],\n",
       "\n",
       "        [[-13.1558,  -8.1435, -13.9676,  ...,  -5.9412,   4.7365,  -1.6542],\n",
       "         [  0.5278,  -0.9536,  -0.2248,  ...,  -9.4538,  12.2925,   2.9705],\n",
       "         [ -9.0265,   4.6353, -10.9682,  ...,  -0.7032,  -4.5731,   2.2254],\n",
       "         ...,\n",
       "         [-11.6344, -22.0302,  13.4817,  ...,   0.9229, -11.3428,   3.5999],\n",
       "         [-10.2158,  -7.3159,  -5.3098,  ...,  -1.8188,   2.1642,   0.6675],\n",
       "         [  0.5082,  -1.2744,   1.7287,  ..., -15.0612,   0.4982,   1.3467]],\n",
       "\n",
       "        [[ 13.1014,  -4.2809,   0.6176,  ...,  -5.5898,  -7.1438,  -8.4322],\n",
       "         [  0.1345, -12.6123,   1.9771,  ...,   5.1996,   4.4117,   7.1020],\n",
       "         [ 10.8376,   6.1763,  -8.5432,  ...,  14.5832,  10.4329,   0.3338],\n",
       "         ...,\n",
       "         [ -0.1872,   6.6343,  -4.0443,  ...,  11.3591,  -5.9625, -12.8465],\n",
       "         [  9.7554,   6.9368,   6.4162,  ...,  -4.0429, -18.6827,  -6.7793],\n",
       "         [ -2.9788, -26.8735,  -3.9925,  ...,   2.4302,   1.6868,  -8.5929]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 11.2923,  -1.4338,  -3.5942,  ...,  -1.1350,  -7.9018,   6.1993],\n",
       "         [  6.7559,  -5.1338,  -4.5478,  ...,   8.8851,   7.4993,   5.9273],\n",
       "         [ -5.3174,   5.2259,   7.4833,  ...,   2.8757,  -6.7549,  -3.1897],\n",
       "         ...,\n",
       "         [ -7.1008,   1.7666,   2.5290,  ...,  -4.6282,  -0.6044,  -3.3652],\n",
       "         [  1.2320,  -7.2849,   5.8909,  ...,   3.8328,   6.4165,  -8.8131],\n",
       "         [ -6.6803,  -4.5998,  -5.6652,  ...,  -7.0898,  -8.4192,  13.2523]],\n",
       "\n",
       "        [[  5.9689, -15.7887,  12.7100,  ..., -13.4702,   3.6596,   3.9813],\n",
       "         [  8.9029,  -1.2387,   8.6786,  ...,  -1.4271,   3.6059,   2.1924],\n",
       "         [  6.8826,   0.8531,   0.7598,  ...,   2.3938,  -2.2027,  -2.8686],\n",
       "         ...,\n",
       "         [  0.4928,  -6.9724,   8.1892,  ..., -11.5544,  -7.2773,  -9.2627],\n",
       "         [  2.1603,   0.7900,   9.4808,  ...,  -9.5289,  -6.2664,  -8.5876],\n",
       "         [  0.8366,   3.8589,   8.1790,  ...,   3.1212,   1.5668,   4.6073]],\n",
       "\n",
       "        [[ -1.2193, -13.4946,  -4.7613,  ...,  13.3276,   2.0477,  -3.6416],\n",
       "         [  1.8547,   6.6799,  -1.1238,  ...,   4.3065,   3.2585, -13.3449],\n",
       "         [ 11.9132,  13.3627,  -7.3988,  ...,  19.3049,   9.0400,  14.5307],\n",
       "         ...,\n",
       "         [ 14.4567,  10.5806,   2.9871,  ...,   3.8045, -12.1498,   7.4985],\n",
       "         [ 11.3034,  -0.4203,   5.0116,  ...,   9.9463,  -0.5252,   3.0596],\n",
       "         [ -8.2772,  -4.5019,  -5.2945,  ...,  11.9172,  27.7796,  -1.6528]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn.functional.conv1d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)\n",
    "# 对几个输入平面组成的输入信号应用1D卷积。\n",
    "fliters = Variable(torch.randn(33,16,3))\n",
    "inputs = Variable(torch.randn(20,16,50))\n",
    "F.conv1d(inputs,fliters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -7.6366,   1.5845,  -0.5984,  -4.4532,  -2.5032],\n",
       "          [ -1.4687,   0.2171,  -6.5862,  -0.6658,  -5.1287],\n",
       "          [  6.5757,   7.3364,   3.2489,  -2.9147,   8.7382],\n",
       "          [  6.6041,   2.9069,  -4.6230,   3.7042,  -4.6457],\n",
       "          [ -1.8336,   1.0205,  -2.1020,  -2.6842,  -1.2131]],\n",
       "\n",
       "         [[  5.1350,   5.8458,  -6.6952,  -2.9227,   2.5235],\n",
       "          [ -7.7761,  -0.8859,  -3.6880,  -4.8251,   1.9459],\n",
       "          [  0.6416,   0.2382, -13.4336,  -3.8464,  -0.8379],\n",
       "          [  0.2105,  -9.7487,   6.1228,  -4.4833,   6.8832],\n",
       "          [  3.6496,  10.8748, -12.9969,   7.6911,   1.8598]],\n",
       "\n",
       "         [[ -0.3487,  -8.5946,  -0.8449,  -0.1845,  -0.1193],\n",
       "          [  1.9774,  -7.3834,   2.2845, -10.0923,   2.7557],\n",
       "          [  1.5404,   1.3552,  -4.1357,   3.4619,  -4.7273],\n",
       "          [  7.7184,  -1.5409,   6.7549,  -7.3993,   5.0917],\n",
       "          [  6.6635,  -0.1140,   5.6164,  -7.8549,   5.3558]],\n",
       "\n",
       "         [[ -1.7561,  -2.3363,   6.8524,   0.6251,   2.2231],\n",
       "          [  0.5403,   0.2693,   1.2932,  -2.2482,   3.7711],\n",
       "          [ -6.2234,  -4.3761,   2.0612,   1.3324,  -0.0505],\n",
       "          [  0.8048,  -5.2100,  -0.2590,  -3.4559,   5.2453],\n",
       "          [  1.0647,  -6.1515,   4.3052,  -5.9271,   3.9816]],\n",
       "\n",
       "         [[  5.0685,   6.0023,  -0.2338,  -1.2562,  -1.2298],\n",
       "          [  4.2304,  -3.2242,  -8.5474,  -1.4279,  -4.5181],\n",
       "          [ -5.2530,  -3.5637,  -7.7688,   2.1794,   0.7143],\n",
       "          [ -3.3370,  -9.0899,  -3.4062,  -2.3425,  -3.6307],\n",
       "          [ -2.9192,  -3.7402,   7.3057,   0.1954,  -2.3005]],\n",
       "\n",
       "         [[  3.4885,   4.0160,  -0.1082,  -4.6769,  -1.5835],\n",
       "          [  0.4276,  -3.2665,  -6.7555,  -1.6455,  -4.8893],\n",
       "          [  2.9984,  -1.0576,  -4.7840,  -0.4703,   2.3106],\n",
       "          [  2.9152,   0.0348,   1.0117,  -9.0245,  -5.9154],\n",
       "          [ -1.8457,   1.9276,   2.7153,   1.8158,  -1.1833]],\n",
       "\n",
       "         [[ -4.9571,   1.3131,   2.5689,  -2.4242,  -0.2690],\n",
       "          [ -0.3852,   0.7574, -13.7271,  -2.2444,  -4.0673],\n",
       "          [  0.1560,  -1.1346,   6.8091,  -8.2899,  -0.5053],\n",
       "          [  4.8119,   1.7865,  -9.7879,   8.3927,   6.0261],\n",
       "          [  4.2201,   4.3262,   3.4167,  -7.5766,  -4.0695]],\n",
       "\n",
       "         [[ -0.0963,  -0.9919,   4.2949,  -3.1863,  -1.8611],\n",
       "          [  1.9184,  -5.5795,  -8.3364,  -2.4050,  -1.0411],\n",
       "          [  1.6515,  -9.8781,   1.8249,  -8.9900,  -0.6590],\n",
       "          [ -1.8628,   5.4639,  -0.5031,   2.2746,  -2.6625],\n",
       "          [  4.1875,  -3.4883,   1.4067,  -1.5267,   2.0636]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)\n",
    "# 对几个输入平面组成的输入信号应用2D卷积。\n",
    "filters = Variable(torch.randn(8,4,3,3))\n",
    "inputs = Variable(torch.randn(1,4,5,5))\n",
    "F.conv2d(inputs, filters, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 4., 6.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn.functional.avg_pool1d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)\n",
    "# 对由几个输入平面组成的输入信号进行一维平均池化。\n",
    "input = Variable(torch.Tensor([[[1,2,3,4,5,6,7]]]))\n",
    "F.avg_pool1d(input, kernel_size=3, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.functional.avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)\n",
    "# 在kh x kw区域中应用步长为dh x dw的二维平均池化操作。输出特征的数量等于输入平面的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.functional.max_pool1d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)\n",
    "# torch.nn.functional.max_pool2d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.Variable\n",
    "# 包装一个Tensor,并记录用在它身上的operations。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward(* input)\n",
    "# 执行operation。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
