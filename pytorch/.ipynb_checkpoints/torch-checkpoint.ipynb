{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果obj 是一个pytorch张量，则返回True\n",
    "torch.is_tensor(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如何obj 是一个pytorch storage对象，则返回True\n",
    "torch.is_storage(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回input 张量中的元素个数\n",
    "torch.numel(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.eye(n, m=None, out=None)\n",
    "#返回一个2维张量，对角线位置全1，其它位置全0\n",
    "# n (int ) – 行数\n",
    "# m (int, optional) – 列数.如果为None,则默认为n\n",
    "# out (Tensor, optinal) - Output tensor\n",
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将numpy.ndarray 转换为pytorch的 Tensor\n",
    "torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回一个1维张量，包含在区间start 和 end 上均匀间隔的steps个点。 输出1维张量的长度为steps\n",
    "torch.linspace(3, 10, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回一个1维张量，包含在区间 10^start 和 10^end上以对数刻度均匀间隔的steps个点。 输出1维张量的长度为steps\n",
    "torch.logspace(start=-10, end=10, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回一个全为1 的张量，形状由可变参数sizes定义。\n",
    "torch.ones(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回一个张量，包含了从区间[0,1)的均匀分布中抽取的一组随机数，形状由可变参数sizes 定义。\n",
    "torch.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn(*sizes, out=None):返回一个张量，包含了从标准正态分布(均值为0，方差为 1，即高斯白噪声)中抽取一组随机数，形状由可变参数sizes定义。\n",
    "torch.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randperm(n, out=None):给定参数n，返回一个从0 到n -1 的随机整数排列。\n",
    "torch.randperm(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.arange(start, end, step=1, out=None):返回一个1维张量，长度为 floor((end−start)/step)。包含从start到end，以step为步长的一组序列值(默认步长为1)。\n",
    "torch.arange(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(1,2.5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.zeros(*sizes, out=None):返回一个全为标量 0 的张量，形状由可变参数sizes 定义。\n",
    "torch.zeros(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cat(inputs, dimension=0):在给定维度上对输入的张量序列seq 进行连接操作。\n",
    "torch.cat((x,x,x),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((x,x,x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.chunk(tensor, chunks, dim=0):在给定维度(轴)上将输入张量进行分块儿。\n",
    "# chunks (int) – 分块的个数\n",
    "torch.chunk(x,2,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.gather(input, dim, index, out=None):沿给定轴dim，将输入索引张量index指定位置的值进行聚合。\n",
    "t = torch.Tensor([[1,2],[3,4]])\n",
    "torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.index_select(input, dim, index, out=None):沿着指定维度对输入进行切片，取index中指定的相应项(index为一个LongTensor)，然后返回到一个新的张量， 返回的张量与原始张量_Tensor_有相同的维度(在指定轴上)。\n",
    "x = torch.randn(3, 4)\n",
    "indices = torch.LongTensor([0, 2])\n",
    "torch.index_select(x, 0, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.index_select(x, 1, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.masked_select(input, mask, out=None):根据掩码张量mask中的二元值，取输入张量中的指定项( mask为一个 ByteTensor)，将取值返回到一个新的1D张量，\n",
    "# 张量 mask须跟input张量有相同数量的元素数目，但形状或维度不需要相同。 注意： 返回的张量不与原始张量共享内存空间。\n",
    "x = torch.randn(3,4)\n",
    "torch.masked_select(x, x<0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nonzero(input, out=None):返回一个包含输入input中非零元素索引的张量。输出张量中的每行包含输入中非零元素的索引。\n",
    "torch.nonzero(torch.Tensor([1,1,1,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nonzero(torch.Tensor([[0.6, 0.0, 0.0, 0.0],\n",
    "                            [0.0, 0.4, 0.0, 0.0],\n",
    "                            [0.0, 0.0, 1.2, 0.0],\n",
    "                            [0.0, 0.0, 0.0,-0.4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.split(tensor, split_size, dim=0):将输入张量分割成相等形状的chunks（如果可分）。 如果沿指定维的张量形状大小不能被split_size 整分， 则最后一个分块会小于其它分块。\n",
    "torch.split(x,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.squeeze(input, dim=None, out=None):将输入张量形状中的1 去除并返回。 如果输入是形如(A×1×B×1×C×1×D)，那么输出形状就为： (A×B×C×D)\n",
    "x = torch.zeros(2,1,2,1,2)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.squeeze(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.squeeze(x,0)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.squeeze(x,1)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5164,  0.3593, -0.8906,  1.2065],\n",
       "         [-0.2938,  0.6807,  1.7413, -0.0682],\n",
       "         [ 1.6914,  2.1806,  0.5833,  0.3230]],\n",
       "\n",
       "        [[ 0.5063, -0.3016,  1.7827, -1.1188],\n",
       "         [ 0.3674, -0.0205,  0.4490, -0.0170],\n",
       "         [-1.9852, -2.2430, -0.3455,  0.0682]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.stack(sequence, dim=0):沿着一个新维度对输入张量序列进行连接。 序列中所有的张量都应该为相同形状。\n",
    "x = torch.randn(3,4)\n",
    "y = torch.randn(3,4)\n",
    "torch.stack((x,y),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3656, -0.7090],\n",
       "        [ 1.0618,  0.1286],\n",
       "        [ 0.2257, -0.7042]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.t(input, out=None)：输入一个矩阵（2维张量），并转置0, 1维。 可以被视为函数transpose(input, 0, 1)的简写函数。\n",
    "x = torch.randn(2,3)\n",
    "torch.t(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0605, -0.3239, -0.6967, -1.1771],\n",
       "         [ 0.9360,  1.5025, -0.9260,  2.2832]],\n",
       "\n",
       "        [[ 1.2940, -0.2201, -0.4184,  2.0980],\n",
       "         [ 1.4440, -1.7725,  0.3953,  0.3332]],\n",
       "\n",
       "        [[ 0.2808, -2.0825, -0.6866,  1.3149],\n",
       "         [ 1.9524, -1.2029, -0.0279,  2.2875]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.transpose(input, dim0, dim1, out=None):返回输入矩阵input的转置。交换维度dim0和dim1。 输出张量与输入张量共享内存，所以改变其中一个会导致另外一个也被修改。\n",
    "x = torch.randn(2,3,4)\n",
    "torch.transpose(x,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.6332,  1.2382]),\n",
       " tensor([0.6597, 0.3962]),\n",
       " tensor([0.1928, 0.3471]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unbind(tensor, dim=0)[source]:移除指定维后，返回一个元组，包含了沿着指定维切片后的各个切片\n",
    "x = torch.randn(2,3)\n",
    "torch.unbind(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x123985175d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.manual_seed(seed):设定生成随机数的种子，并返回一个 torch._C.Generator 对象.\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.initial_seed():返回生成随机数的原始种子值（python long）。\n",
    "torch.initial_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0,  ..., 0, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.get_rng_state()[source]:返回随机生成器状态(ByteTensor)\n",
    "torch.get_rng_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x123985175d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.default_generator:获取默认的Generator实例\n",
    "torch.default_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.bernoulli(input, out=None):从伯努利分布中抽取二元随机数(0 或者 1)。\n",
    "a = torch.Tensor(3, 3).uniform_(0, 1)\n",
    "torch.bernoulli(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(3,3)\n",
    "torch.bernoulli(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 0, 3])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.multinomial(input, num_samples,replacement=False, out=None):返回一个张量，每行包含从input相应行中定义的多项分布中抽取的num_samples个样本。\n",
    "# replacement (bool, optional) – 布尔值，决定是否能重复抽取\n",
    "weights = torch.Tensor([0,10,3,0])\n",
    "torch.multinomial(weights,4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 1, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(weights,4,replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8692, 1.0095, 1.1146, 0.9962],\n",
       "        [1.0932, 1.0529, 0.8471, 1.0223],\n",
       "        [0.8593, 0.9773, 1.0470, 0.9691]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.normal(means, std,size,*, out=None):返回一个张量，包含从给定参数means,std的离散正态分布中抽取随机数。\n",
    "torch.normal(mean=1,std=0.1,size=(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.abs(input, out=None):计算输入张量的每个元素绝对值\n",
    "torch.abs(torch.FloatTensor([-1,-2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.4916, 1.5454, 0.7992,    nan])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.acos(input, out=None) :返回一个新张量，包含输入张量每个元素的反余弦。\n",
    "a = torch.randn(4)\n",
    "torch.acos(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19.2039, 20.0254, 20.6973, 18.4885])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.add(input, value, out=None):对输入张量input逐元素加上标量值value，并返回结果到一个新的张量out，即 out=tensor+value。\n",
    "torch.add(a,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.add(input, value=1, other, out=None):other 张量的每个元素乘以一个标量值value，并加到input 张量上。返回结果到输出张量out。即，out=input+(other∗value)\n",
    "# input和other形状要匹配\n",
    "a = torch.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17.1078, -1.4653,  3.7808,  2.3342])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(a,10,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0342,  0.3013, -0.5940, -1.6065,  4.5766,  1.2342]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None)：用tensor2对tensor1逐元素相除，然后乘以标量值value 并加到tensor。\n",
    "# tensor,tensor1,tensor2形状要匹配\n",
    "t = torch.randn(1, 6)\n",
    "t1 = torch.randn(1, 6)\n",
    "t2 = torch.randn(1, 6)\n",
    "torch.addcdiv(t, 0.1, t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2165,  0.2497, -0.6322, -1.6701,  0.0362,  1.1993]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.addcmul(tensor, value=1, tensor1, tensor2, out=None)：用tensor2对tensor1逐元素相乘，并对结果乘以标量值value然后加到tensor\n",
    "# 形状要匹配\n",
    "torch.addcmul(t, 0.1, t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2796,     nan, -0.2226,  0.0901])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.asin(input, out=None):返回一个新张量，包含输入input张量每个元素的反正弦函数\n",
    "a = torch.randn(4)\n",
    "torch.asin(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2693, -0.9811, -0.2173,  0.0898])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.atan(input, out=None):返回一个新张量，包含输入input张量每个元素的反正切函数\n",
    "torch.atan(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.0191, -1.9494, -0.7348,  0.0718])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.atan2(input1, input2, out=None):返回一个新张量，包含两个输入张量input1和input2的反正切函数\n",
    "torch.atan2(a,torch.randn(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1., -1., -0.,  1.])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.ceil(input, out=None):对输入input张量每个元素向上取整, 即取不小于每个元素的最小整数，并返回结果到输出。\n",
    "torch.ceil(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2760, -0.5000, -0.2208,  0.0900])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.clamp(input, min, max, out=None):将输入input张量每个元素的夹紧到区间 [min,max]，并返回结果到一个新张量。\n",
    "torch.clamp(a,min=-0.5,max=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000, 0.5000, 0.5000])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.clamp(input, *, min, out=None):将输入input张量每个元素的限制到不小于min ，并返回结果到一个新张量。\n",
    "torch.clamp(a,min=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2760, -1.4947, -0.2208,  0.0900])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.clamp(input, *, max, out=None):将输入input张量每个元素的限制到不大于max ，并返回结果到一个新张量。\n",
    "torch.clamp(a,max=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9622, 0.0761, 0.9757, 0.9960])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cos(input, out=None):返回一个新张量，包含输入input张量每个元素的余弦。\n",
    "torch.cos(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0383, 2.3411, 1.0245, 1.0041])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cosh(input, out=None):返回一个新张量，包含输入input张量每个元素的双曲余弦。\n",
    "torch.cosh(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1331,  3.9370, -1.3428,  6.3687, -3.1204])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.div(input, value, out=None):将input逐元素除以标量值value，并返回结果到输出张量out。 即 out=tensor/value\n",
    "a = torch.randn(5)\n",
    "torch.div(a,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.7140,  0.9888, -0.1909, -2.3848],\n",
       "        [10.9430, 12.8432,  0.4564,  0.4160],\n",
       "        [ 3.9529,  2.3070, -0.2870,  0.2725],\n",
       "        [-1.1345,  1.4058, -1.1445,  0.1892]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.div(input, other, out=None):两张量input和other逐元素相除，并将结果返回到输出。即， outi=inputi/otheri\n",
    "a = torch.randn(4,4)\n",
    "b = torch.randn(4,4)\n",
    "torch.div(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.exp(tensor, out=None):返回一个新张量，包含输入input张量每个元素的指数。\n",
    "import math\n",
    "torch.exp(torch.Tensor([0, math.log(2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.floor(input, out=None):向下取整\n",
    "a = torch.randn(4)\n",
    "torch.floor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -0., -1.,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.fmod(input, divisor, out=None):计算除法余数。 除数与被除数可能同时含有整数和浮点数。此时，余数的正负与被除数相同。\n",
    "torch.fmod(torch.Tensor([-3,-2,-1,1,2,3]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.5000, 0.0000, 1.0000, 0.5000])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.fmod(torch.Tensor([1, 2, 3, 4, 5]), 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.5000, -0.2000])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.frac(tensor, out=None):返回每个元素的分数部分。\n",
    "torch.frac(torch.Tensor([1,2.5,-3.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 6.0000, 6.5000, 7.0000])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.lerp(start, end, weight, out=None):对两个张量以start，end做线性插值， 将结果返回到输出张量。即，outi=starti+weight∗(endi−starti)\n",
    "start = torch.arange(1,5.0)\n",
    "end = torch.Tensor(4).fill_(10)\n",
    "torch.lerp(start,end,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   nan,    nan, 0.2094,    nan,    nan])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.log(input, out=None):计算input 的自然对数\n",
    "a = torch.randn(5)\n",
    "torch.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5137,     nan,  0.8033, -0.8155,     nan])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.log1p(input, out=None):计算 input+1的自然对数 yi=log(xi+1)\n",
    "torch.log1p(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2052, -5.7083,  3.6988, -1.6728, -3.2567])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mul(input, value, out=None):用标量值value乘以输入input的每个元素，并返回一个新的结果张量。 out=tensor∗value\n",
    "torch.mul(a,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2655, -0.2228,  0.6209, -0.0175],\n",
       "        [ 0.3911,  0.6894,  0.8245, -0.0039],\n",
       "        [ 2.5612,  0.0678, -0.0053,  1.2573],\n",
       "        [ 0.0472,  0.1553, -0.0655,  0.9583]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mul(input, other, out=None)：两个张量input,other按元素进行相乘，并返回到输出张量。即计算outi=inputi∗otheri\n",
    "a = torch.randn(4,4)\n",
    "b = torch.randn(4,4)\n",
    "torch.mul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3680, -0.0750, -0.0560, -1.4534,  0.4021])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.neg(input, out=None):返回一个新张量，包含输入input 张量按元素取负。 即， out=−1∗input\n",
    "a = torch.randn(5)\n",
    "torch.neg(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1354, 0.0056, 0.0031, 2.1122, 0.1617])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.pow(input, exponent, out=None):对输入input的按元素求exponent次幂值，并返回结果张量。 幂值exponent 可以为单一 float 数或者与input相同元素数的张量。\n",
    "torch.pow(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,   4,  27, 256])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = torch.arange(1,5)\n",
    "a = torch.arange(1,5)\n",
    "torch.pow(a,exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  4,  8, 16])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.pow(base, input, out=None):base 为标量浮点值,input为张量， 返回的输出张量 out 与输入张量相同形状。\n",
    "exp = torch.arange(1,5)\n",
    "base = 2\n",
    "torch.pow(base,exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8088, -2.4706, -1.4675,  1.2739])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.reciprocal(input, out=None):返回一个新张量，包含输入input张量每个元素的倒数，即 1.0/x。\n",
    "a = torch.randn(4)\n",
    "torch.reciprocal(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., -0., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.remainder(input, divisor, out=None):返回一个新张量，包含输入input张量每个元素的除法余数。 除数与被除数可能同时包含整数或浮点数。余数与除数有相同的符号。\n",
    "torch.remainder(torch.Tensor([-3, -2, -1, 1, 2, 3]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.5000, 0.0000, 1.0000, 0.5000])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.remainder(torch.Tensor([1, 2, 3, 4, 5]), 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  1.,  0., -1.])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.round(input, out=None):返回一个新张量，将输入input张量每个元素舍入到最近的整数。\n",
    "a = torch.randn(4)\n",
    "torch.round(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   nan, 1.3411, 4.0672,    nan])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.rsqrt(input, out=None):返回一个新张量，包含输入input张量每个元素的平方根倒数。\n",
    "torch.rsqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2771, 0.6355, 0.5151, 0.1896])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.sigmoid(input, out=None):返回一个新张量，包含输入input张量每个元素的sigmoid值。\n",
    "torch.sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  1.,  1., -1.])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.sign(input, out=None):返回一个新张量，包含输入input张量每个元素的正负。\n",
    "torch.sign(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8187,  0.5278,  0.0604, -0.9930])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.sin(input, out=None):返回一个新张量，包含输入input张量每个元素的正弦。\n",
    "torch.sin(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1131,  0.5851,  0.0605, -2.0200])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.sinh(input, out=None):返回一个新张量，包含输入input张量每个元素的双曲正弦。\n",
    "torch.sinh(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   nan, 0.7457, 0.2459,    nan])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.sqrt(input, out=None):返回一个新张量，包含输入input张量每个元素的平方根。\n",
    "torch.sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4257,  0.6214,  0.0605, -8.4168])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.tan(input, out=None):返回一个新张量，包含输入input张量每个元素的正切。\n",
    "torch.tan(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7439,  0.5050,  0.0604, -0.8962])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.tanh(input, out=None):返回一个新张量，包含输入input张量每个元素的双曲正切。\n",
    "torch.tanh(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.,  0.,  0., -1.])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.trunc(input, out=None):返回一个新张量，包含输入input张量每个元素的截断值(标量x的截断值是最接近其的整数，其比x更接近零。简而言之，有符号数的小数部分被舍弃)。\n",
    "torch.trunc(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cumprod(input, dim, out=None):返回输入沿指定维度的累积积。例如，如果输入是一个N 元向量，则结果也是一个N 元向量，第i 个输出元素值为yi=x1∗x2∗x3∗...∗xi\n",
    "a = torch.arange(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     1,      2,      6,     24,    120,    720,   5040,  40320, 362880])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cumprod(a,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  3,  6, 10, 15, 21, 28, 36, 45])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cumsum(input, dim, out=None):返回输入沿指定维度的累积和。例如，如果输入是一个N元向量，则结果也是一个N元向量，第i 个输出元素值为 yi=x1+x2+x3+...+xi\n",
    "torch.cumsum(a,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6367)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.dist(input, other, p=2, out=None):返回 (input - other) 的 p范数 。\n",
    "x = torch.randn(4)\n",
    "y = torch.randn(4)\n",
    "torch.dist(x,y,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3197)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mean(input):返回输入张量所有元素的均值。\n",
    "a = torch.randn(1,3)\n",
    "torch.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7597,  0.3708, -0.8389,  0.6148])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mean(input, dim, out=None):返回输入张量给定维度dim上每行的均值。\n",
    "a = torch.randn(4,4)\n",
    "torch.mean(a,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3414, -0.2629, -0.1171, -0.5745])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.median(\n",
       "values=tensor([ 0.4533, -0.0446, -0.8894,  0.2517]),\n",
       "indices=tensor([3, 1, 0, 3]))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.median(input, dim=-1, values=None, indices=None):返回输入张量给定维度每行的中位数，同时返回一个包含中位数的索引的LongTensor。\n",
    "# dim值默认为输入张量的最后一维。 输出形状与输入相同，除了给定维度上为1.\n",
    "a = torch.randn(4,5)\n",
    "torch.median(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.median(\n",
       "values=tensor([-0.6885, -0.8092, -0.8091,  0.2517,  0.4817]),\n",
       "indices=tensor([1, 2, 1, 3, 0]))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.median(a,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.median(\n",
       "values=tensor([ 0.4533, -0.0446, -0.8894,  0.2517]),\n",
       "indices=tensor([3, 1, 0, 3]))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.median(a,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.mode(\n",
       "values=tensor([-1.1615, -0.8091, -1.0441, -0.5870]),\n",
       "indices=tensor([1, 2, 2, 0]))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mode(input, dim=-1, values=None, indices=None):返回给定维dim上，每行的众数值。 同时返回一个LongTensor，包含众数职的索引。dim值默认为输入张量的最后一维。\n",
    "torch.mode(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6695)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.norm(input, p=2):返回输入张量input 的p 范数。\n",
    "a = torch.randn(1,3)\n",
    "torch.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7707, 1.3063, 2.2908, 1.2949])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.norm(input, p, dim, out=None):返回输入张量给定维dim 上每行的p 范数。 输出形状与输入相同，除了给定维度上为1.\n",
    "a = torch.randn(4,2)\n",
    "torch.norm(a,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2.])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(a,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0041)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.prod(input):返回输入张量input 所有元素的积。\n",
    "torch.prod(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1774, -0.8525,  0.0415, -0.6601])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.prod(input, dim, out=None):返回输入张量给定维度上每行的积。 输出形状与输入相同，除了给定维度上为1.\n",
    "torch.prod(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6470)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.std(input):返回输入张量input 所有元素的标准差。\n",
    "a = torch.randn(1,3)\n",
    "torch.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8050, 0.5655, 0.8125, 0.4404])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.std(input, dim, out=None):返回输入张量给定维度上每行的标准差。 输出形状与输入相同，除了给定维度上为1.\n",
    "a = torch.randn(4,4)\n",
    "torch.std(a,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.1029)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.sum(input):返回输入张量input 所有元素的和。\n",
    "a = torch.randn(1,3)\n",
    "torch.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.3098, -3.6671, -2.2698, -0.1188])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.sum(input, dim, out=None):返回输入张量给定维度上每行的和。 输出形状与输入相同，除了给定维度上为1.\n",
    "a = torch.randn(4,4)\n",
    "torch.sum(a,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3260)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.var(input):返回输入张量所有元素的方差.输出形状与输入相同，除了给定维度上为1.\n",
    "a = torch.randn(1,3)\n",
    "torch.var(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0857, 0.9206, 0.6915, 0.1974])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.var(input, dim, out=None):返回输入张量给定维度上每行的方差。 输出形状与输入相同，除了给定维度上为1.\n",
    "a = torch.randn(4,4)\n",
    "torch.var(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False],\n",
       "        [False,  True]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.eq(input, other, out=None):比较元素相等性。第二个参数可为一个数或与第一个参数同类型形状的张量。\n",
    "torch.eq(torch.Tensor([[1,2],[3,4]]),torch.Tensor([[1,1],[4,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False],\n",
       "        [ True, False]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(torch.Tensor([[1,2],[3,4]]),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.equal(tensor1, tensor2):如果两个张量有相同的形状和元素值，则返回True ，否则 False。\n",
    "torch.equal(torch.Tensor([1, 2]), torch.Tensor([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True],\n",
       "        [False,  True]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.ge(input, other, out=None):逐元素比较input和other，即是否 input>=other。\n",
    "torch.ge(torch.Tensor([[1,2],[3,4]]),torch.Tensor([[1,1],[4,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True],\n",
       "        [False, False]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.gt(input, other, out=None):逐元素比较input和other ， 即是否input>other 如果两个张量有相同的形状和元素值，则返回True ，否则 False。 \n",
    "#第二个参数可以为一个数或与第一个参数相同形状和类型的张量\n",
    "torch.gt(torch.Tensor([[1,2],[3,4]]),torch.Tensor([[1,1],[4,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.kthvalue(\n",
       "values=tensor([ 0.1839, -0.8319, -0.3066]),\n",
       "indices=tensor([3, 1, 0]))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.kthvalue(input, k, dim=None, out=None):取输入张量input指定维上第k 个最小值。如果不指定dim，则默认为input的最后一维。\n",
    "# 返回一个元组 (values,indices)，其中indices是原始输入张量input中沿dim维的第 k 个最小值下标。\n",
    "x = torch.randn(3,4)\n",
    "torch.kthvalue(x,2,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.le(input, other, out=None):逐元素比较input和other,即是否input<=other 第二个参数可以为一个数或与第一个参数相同形状和类型的张量\n",
    "torch.le(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False],\n",
       "        [ True, False]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.lt:逐元素比较input和other,即是否 input<other.第二个参数可以为一个数或与第一个参数相同形状和类型的张量\n",
    "torch.lt(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1564)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.max():返回输入张量所有元素的最大值。\n",
    "a = torch.randn(1, 3)\n",
    "torch.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.4210, 1.7252, 0.6357, 2.0859]),\n",
       "indices=tensor([1, 0, 1, 1]))"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.max(input, dim, max=None, max_indices=None):返回输入张量给定维度上每行的最大值，并同时返回每个最大值的位置索引。\n",
    "a = torch.randn(4, 4)\n",
    "torch.max(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1949, -0.5887, -0.0461,  0.5770])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.max(input, other, out=None):返回输入张量给定维度上每行的最大值，并同时返回每个最大值的位置索引。 即，outi=max(inputi,otheri)\n",
    "a = torch.randn(4)\n",
    "b = torch.randn(4)\n",
    "torch.max(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.5369)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.min(input):返回输入张量所有元素的最小值。\n",
    "a = torch.randn(1,3)\n",
    "torch.min(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([-1.5227, -1.8560, -0.3681]),\n",
       "indices=tensor([0, 3, 0]))"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.min(input, dim, min=None, min_indices=None):\n",
    "# min (Tensor, optional) – 结果张量，包含给定维度上的最小值\n",
    "# min_indices (LongTensor, optional) – 结果张量，包含给定维度上每个最小值的位置索引\n",
    "a = torch.randn(3,4)\n",
    "torch.min(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0844, -1.7622, -0.5260, -0.1137])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.min(input, other, out=None):input中逐元素与other相应位置的元素对比，返回最小值到输出张量。即，outi=min(tensori,otheri)\n",
    "a = torch.randn(4)\n",
    "b = torch.randn(4)\n",
    "torch.min(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True],\n",
       "        [ True, False]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.ne(input, other, out=None):逐元素比较input和other，即是否 input!=other。 第二个参数可以为一个数或与第一个参数相同形状和类型的张量\n",
    "torch.ne(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.sort(input, dim=None, descending=False, out=None):对输入张量input沿着指定维按升序排序。如果不给定dim，则默认为输入的最后一维。如果指定参数descending为True，则按降序排序\n",
    "# 返回元组 (sorted_tensor, sorted_indices) ， sorted_indices 为原始输入中的下标。\n",
    "x = torch.randn(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[-0.2965,  0.6041,  0.7885,  1.3493],\n",
       "        [-3.1786, -0.5718,  0.1265,  0.1770],\n",
       "        [-1.2562, -1.1070, -0.9786,  0.8458]]),\n",
       "indices=tensor([[2, 1, 0, 3],\n",
       "        [1, 2, 3, 0],\n",
       "        [0, 3, 2, 1]]))"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[-1.2562, -3.1786, -0.9786, -1.1070],\n",
       "        [ 0.1770,  0.6041, -0.5718,  0.1265],\n",
       "        [ 0.7885,  0.8458, -0.2965,  1.3493]]),\n",
       "indices=tensor([[2, 1, 2, 2],\n",
       "        [1, 0, 1, 1],\n",
       "        [0, 2, 0, 0]]))"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([5, 4, 3]),\n",
       "indices=tensor([4, 3, 2]))"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.topk(input, k, dim=None, largest=True, sorted=True, out=None)\n",
    "# 沿给定dim维度返回输入张量input中 k 个最大值。 如果不指定dim，则默认为input的最后一维。 如果为largest为 False ，则返回最小的 k 个值。\n",
    "# 返回一个元组 (values,indices)，其中indices是原始输入张量input中测元素下标。 如果设定布尔值sorted 为_True_，将会确保返回的 k 个值被排序。\n",
    "x = torch.arange(1, 6)\n",
    "torch.topk(x, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([1, 2, 3]),\n",
       "indices=tensor([0, 1, 2]))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(x, 3, 0, largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2989,  0.4032,  0.6617],\n",
       "        [-0.4444, -0.8104, -0.5243],\n",
       "        [-1.9823, -1.1149,  0.6776],\n",
       "        [-0.0217,  0.1352,  0.0486]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cross(input, other, dim=-1, out=None)\n",
    "# 返回沿着维度dim上，两个张量input和other的向量积（叉积）。 input和other 必须有相同的形状，且指定的dim维上size必须为3。\n",
    "# 如果不指定dim，则默认为第一个尺度为3的维。\n",
    "a = torch.randn(4,3)\n",
    "b = torch.randn(4,3)\n",
    "torch.cross(a,b,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9407,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.9898,  0.0000],\n",
       "        [ 0.0000,  0.0000, -0.3677]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.diag(input, diagonal=0, out=None)\n",
    "# 如果输入是一个向量(1D 张量)，则返回一个以input为对角线元素的2D方阵\n",
    "# 如果输入是一个矩阵(2D 张量)，则返回一个包含input对角线元素的1D张量\n",
    "# diagonal = 0, 主对角线\n",
    "# diagonal > 0, 主对角线之上\n",
    "# diagonal < 0, 主对角线之下\n",
    "a = torch.randn(3)\n",
    "torch.diag(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.9407,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.9898,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000, -0.3677],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1979, -0.5450,  2.2667])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9105, -0.0388])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 1., 0.])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.histc(input, bins=100, min=0, max=0, out=None)\n",
    "# 计算输入张量的直方图。以min和max为range边界，将其均分成bins个直条，然后将排序好的数据划分到各个直条(bins)中。\n",
    "# 如果min和max都为0, 则利用数据中的最大最小值作为边界。\n",
    "# input (Tensor) – 输入张量\n",
    "# bins (int) – 直方图 bins(直条)的个数(默认100个)\n",
    "# min (int) – range的下边界(包含)\n",
    "# max (int) – range的上边界(包含)\n",
    "# out (Tensor, optional) – 结果张量\n",
    "torch.histc(torch.FloatTensor([1, 2, 1]), bins=4, min=0, max=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000],\n",
       "        [1.6667, 1.6667, 1.6667],\n",
       "        [1.6667, 1.6667, 1.6667]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.renorm(input, p, dim, maxnorm, out=None):返回一个张量，包含规范化后的各个子张量，使得沿着dim维划分的各子张量的p范数小于maxnorm。\n",
    "# input (Tensor) – 输入张量\n",
    "# p (float) – 范数的p\n",
    "# dim (int) – 沿着此维切片，得到张量子集\n",
    "# maxnorm (float) – 每个子张量的范数的最大值\n",
    "# out (Tensor, optional) – 结果张量\n",
    "x = torch.ones(3, 3)\n",
    "x[1].fill_(2)\n",
    "x[2].fill_(3)\n",
    "torch.renorm(x,1,0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.trace(input):返回输入2维矩阵对角线元素的和(迹)\n",
    "x = torch.arange(1, 10).view(3, 3)\n",
    "torch.trace(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3354,  0.0000,  0.0000],\n",
       "        [-0.5409, -0.0518,  0.0000],\n",
       "        [-0.6847, -0.8095, -1.0921]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.tril(input, diagonal=0, out=None)\n",
    "# 返回一个张量out，包含输入矩阵(2D张量)的下三角部分，out其余部分被设为0。这里所说的下三角部分为矩阵指定对角线diagonal之上的元素。\n",
    "a = torch.randn(3,3)\n",
    "torch.tril(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3354,  0.1013,  0.0000],\n",
       "        [-0.5409, -0.0518,  0.7341],\n",
       "        [-0.6847, -0.8095, -1.0921]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(a, diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [-0.5409,  0.0000,  0.0000],\n",
       "        [-0.6847, -0.8095,  0.0000]])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(a, diagonal=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3354,  0.1013,  0.3645],\n",
       "        [ 0.0000, -0.0518,  0.7341],\n",
       "        [ 0.0000,  0.0000, -1.0921]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.triu(input, k=0, out=None)\n",
    "# 返回一个张量，包含输入矩阵(2D张量)的上三角部分，其余部分被设为0。这里所说的上三角部分为矩阵指定对角线diagonal之上的元素。\n",
    "torch.triu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1013, 0.3645],\n",
       "        [0.0000, 0.0000, 0.7341],\n",
       "        [0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(a,diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3354,  0.1013,  0.3645],\n",
       "        [-0.5409, -0.0518,  0.7341],\n",
       "        [ 0.0000, -0.8095, -1.0921]])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(a,diagonal=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.dot:计算两个张量的点乘(内乘),两个张量都为1-D 向量.\n",
    "torch.dot(torch.Tensor([2, 3]), torch.Tensor([2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.eig(\n",
       "eigenvalues=tensor([[-0.6620,  0.5828],\n",
       "        [-0.6620, -0.5828],\n",
       "        [ 3.6527,  0.0000],\n",
       "        [ 2.3633,  0.0000]]),\n",
       "eigenvectors=tensor([[-0.4967, -0.3573,  0.4282,  0.4423],\n",
       "        [ 0.0851,  0.1067,  0.7798, -0.1430],\n",
       "        [-0.7656,  0.0000, -0.3858, -0.5155],\n",
       "        [-0.1406,  0.0336,  0.2445,  0.7199]]))"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.eig(a, eigenvectors=False, out=None):计算实方阵a 的特征值和特征向量\n",
    "a = torch.randn(4,4)\n",
    "torch.eig(a, eigenvectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6451, -0.6466,  2.4604, -1.3879, -0.9022, -0.1816, -0.1084,  0.6990,\n",
       "         -2.6394,  2.2047],\n",
       "        [-0.8441,  1.1426, -2.6133,  1.9520, -0.3120, -1.2013,  1.1073, -1.5547,\n",
       "          3.8145, -1.7211],\n",
       "        [ 1.9265, -1.2718,  3.2947, -2.9051, -1.1292,  2.0550,  0.3653, -0.5780,\n",
       "         -6.2883,  5.0428],\n",
       "        [ 1.1747, -1.2204,  1.3246, -2.4960,  2.3398,  0.2747, -2.2265, -0.1121,\n",
       "          0.6640,  0.2798],\n",
       "        [-1.8996,  1.3381, -6.1122,  5.2902,  2.0381, -4.2102,  0.7274, -0.9832,\n",
       "          9.0600, -6.3006],\n",
       "        [ 0.7720,  0.1000,  2.8401, -1.2827, -1.7862,  1.4206, -0.0530,  0.0757,\n",
       "         -4.0927,  3.0136],\n",
       "        [-0.9585,  0.8791,  1.0287, -0.2740, -0.5030,  0.0231,  0.5812,  0.9590,\n",
       "         -2.2691,  1.0368],\n",
       "        [-1.4426, -0.5345,  0.9916,  0.1279,  0.9860,  0.3017, -0.5496,  1.1828,\n",
       "          0.4111, -1.0147],\n",
       "        [-0.6177,  0.3119,  0.9615, -0.1649, -1.4718,  2.2663, -0.0566,  2.0577,\n",
       "         -3.1437,  1.2542],\n",
       "        [ 2.1657, -0.3178, -2.1263, -0.3241,  0.3583,  0.7290,  0.3451, -1.3980,\n",
       "          1.6890, -1.4598]])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.inverse(input, out=None)：对方阵输入input 取逆。\n",
    "x = torch.rand(10, 10)\n",
    "torch.inverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9614, -1.1862,  0.5386],\n",
       "        [ 1.0214, -3.1898,  0.5547]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm(mat1, mat2, out=None)：对矩阵mat1和mat2进行相乘。 如果mat1 是一个n×m 张量，mat2 是一个 m×p 张量，将会输出一个 n×p 张量out。\n",
    "mat1 = torch.randn(2, 3)\n",
    "mat2 = torch.randn(3, 3)\n",
    "torch.mm(mat1,mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0490, -1.3494])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mv:对矩阵mat和向量vec进行相乘。 如果mat 是一个n×m张量，vec 是一个m元 1维张量，将会输出一个n 元 1维张量。\n",
    "mat = torch.randn(2,3)\n",
    "vec = torch.randn(3)\n",
    "torch.mv(mat,vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.qr(input, out=None):计算输入矩阵的QR分解：返回两个矩阵q ,r， 使得 x=q∗r ，这里q 是一个半正交矩阵与 r 是一个上三角矩阵\n",
    "a = torch.Tensor([[12, -51, 4], [6, 167, -68], [-4, 24, -41]])\n",
    "q,r = torch.qr(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.svd(input, some=True, out=None):U,S,V=torch.svd(A)。 返回对形如 n×m的实矩阵 A 进行奇异值分解的结果，使得 A=USV'∗。 U 形状为 n×n，S 形状为 n×m ，V 形状为 m×m\n",
    "a = torch.Tensor([ [8.79,  6.11, -9.15,  9.57, -3.49,  9.84],\n",
    "                   [9.93,  6.91, -7.93,  1.64,  4.02,  0.15],\n",
    "                   [9.83,  5.04,  4.86,  8.83,  9.80, -8.99],\n",
    "                   [5.45, -0.27,  4.85,  0.74, 10.00, -6.02],\n",
    "                   [3.16,  7.98,  3.01,  5.80,  4.27, -5.31]]).t()\n",
    "u,s,v=torch.svd(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
